{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from transformers import MarianMTModel, MarianTokenizer, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from translate.storage.tmx import tmxfile\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "rawdata_path = '/Users/alexlo/Desktop/Project/Chai_Trans/rawdata/trados_tmx/'\n",
    "workdata_path = '/Users/alexlo/Desktop/Project/Chai_Trans/workdata/'\n",
    "logdata_path = '/Users/alexlo/Desktop/Project/Chai_Trans/logdata'\n",
    "os.chdir(rawdata_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmx_to_df(path: str, from_: str, to_:str) -> pd.DataFrame:\n",
    "    with open(path, 'rb') as fin:\n",
    "        tmx_file = tmxfile(fin, from_, to_)\n",
    "    data = []\n",
    "    for node in tmx_file.unit_iter():\n",
    "        data.append([node.source, node.target])\n",
    "    df = pd.DataFrame(data, columns=[from_, to_])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = 'CH(Simplified)-EN.tmx'\n",
    "file2 = 'CH(Simplified)-EN_who.tmx'\n",
    "df1 = tmx_to_df(file1, 'zh', 'en')\n",
    "df2 = tmx_to_df(file2, 'zh', 'en')\n",
    "df = pd.concat([df1, df2], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48894, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zh</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>焦距調節機構</td>\n",
       "      <td>FOCAL LENGTH ADJUSTMENT MECHANISM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一種焦距調節機構，適於調節位於一投影機的一殼體內的一焦距調節件。</td>\n",
       "      <td>A focal length adjustment mechanism, adapted f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>焦距調節機構包括一旋鈕及一第一行程調整件。</td>\n",
       "      <td>The focal length adjustment mechanism includes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>旋鈕局部地外露於殼體。</td>\n",
       "      <td>The knob is partially exposed to the housing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>旋鈕轉動，帶動第一行程調整件以第一樞軸為中心轉動。</td>\n",
       "      <td>The knob rotates to drive the first stroke adj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 zh  \\\n",
       "0                            焦距調節機構   \n",
       "1  一種焦距調節機構，適於調節位於一投影機的一殼體內的一焦距調節件。   \n",
       "2             焦距調節機構包括一旋鈕及一第一行程調整件。   \n",
       "3                       旋鈕局部地外露於殼體。   \n",
       "4         旋鈕轉動，帶動第一行程調整件以第一樞軸為中心轉動。   \n",
       "\n",
       "                                                  en  \n",
       "0                  FOCAL LENGTH ADJUSTMENT MECHANISM  \n",
       "1  A focal length adjustment mechanism, adapted f...  \n",
       "2  The focal length adjustment mechanism includes...  \n",
       "3      The knob is partially exposed to the housing.  \n",
       "4  The knob rotates to drive the first stroke adj...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(workdata_path)\n",
    "df.to_json('tmx_zh_en.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset in Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 24447 examples [00:00, 215962.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "os.chdir(workdata_path)\n",
    "raw_datasets = load_dataset('json', data_files='tmx_zh_en.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 試著只用100行來訓練\n",
    "raw_datasets['train'] = raw_datasets['train'].select(range(100, 200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zh': ['此外，在本實施例中，阻尼組件140還設置於第二行程調整件130。',\n",
       "  '具體地說，阻尼組件140的抵壓件142(左方的抵壓件142)設置於第二樞軸135上以對第二樞軸135向下施壓。',\n",
       "  '如此，第一端部121的位置便能夠被保持。',\n",
       "  '因此，第一行程調整件120在第一樞軸127處便會受到抵壓件142的下壓力所形成的摩擦力，而不會隨意轉動。',\n",
       "  '因此，第二行程調整件130在第二樞軸135處便會受到抵壓件142的下壓力所形成的摩擦力而不會隨意轉動，第四端部133的位置便能夠被保持。',\n",
       "  '因此，旋鈕110可連帶地保持位置，待使用者施力轉動旋鈕110，克服上述摩擦力，而可使第二行程調整件130與第一行程調整件120轉動。',\n",
       "  '由圖1可見，阻尼組件140還可選擇地包括一緩衝件144。',\n",
       "  '緩衝件144設置於抵壓件142與第一樞軸127之間，緩衝件144受抵壓件142擠壓變形。',\n",
       "  '這樣的設計可使得抵壓件142透過緩衝件144來調整下壓力，以免第一樞軸127處的摩擦力過大。',\n",
       "  '當然，組裝者也可以透過調整抵壓件142在沿著軸向A的螺接位置，來提供不同的下壓力。'],\n",
       " 'en': ['In addition, in this embodiment, the 140 is also set on the 130.',\n",
       "  'Specifically, the 142 of the 140 (the 142 on the left) is set on the 135 to puts downward pressure on the 135.',\n",
       "  'As a result, the position of the 121 can be remained.',\n",
       "  'Therefore, the 120 on the 127 is subjected to the friction formed by the downward pressure of the 142, and will not rotate freely.',\n",
       "  'Therefore, the 130 on the 135 is subjected to the friction formed by the downward pressure of the 142, and will not rotate freely, the position of the 133 can be remained.',\n",
       "  'As a result, the position of the 110 is also remained, and when the user overcomes the friction described above to rotate the 110, the 130 and the 120 is rotated.',\n",
       "  'As shown in FIG. 1, the 140 may also include a cushioning member 144.',\n",
       "  'The cushioning member 144 is set between the pressing member 142 and the first pivot 127, the cushioning member 144 is deformed by the pressure of the pressing member 142.',\n",
       "  'Such a design enables the 142 to adjust the downward pressure through the 144, so as to prevent the friction on the 127 being excessive.',\n",
       "  'Certainly, assemblers can also provide different downward pressure through adjusting the screwing position along the axis A of the 142.']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['zh', 'en'],\n",
       "        num_rows: 90\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['zh', 'en'],\n",
       "        num_rows: 10\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets = raw_datasets[\"train\"].train_test_split(train_size=0.9, seed=20)\n",
    "split_datasets[\"validation\"] = split_datasets.pop(\"test\")\n",
    "split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zh': '在一實施例中，磁吸件146、147也可以是其中一者是磁鐵，另一者是可被磁鐵吸引的金屬。',\n",
       " 'en': 'In an embodiment, one of the magnetic attraction members 146 and 147 can also be a magnet, while the other one is a metal that can be attracted by the magnet.'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'The second line structure is suitable to connect to another group of connectors.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_checkpoint = \"charliealex123/marian-finetuned-kde4-zh-to-en\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)\n",
    "translator(\"第二組線路結構適合連接另一組接合器。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In an embodiment, one of the magnetic attraction members 146 and 147 can also be a magnet, while the other one is a metal that can be attracted by the magnet.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets[\"train\"][1][\"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:3866: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "zh_sentence = split_datasets[\"train\"][1][\"zh\"]\n",
    "en_sentence = split_datasets[\"train\"][1][\"en\"]\n",
    "\n",
    "inputs = tokenizer(zh_sentence)\n",
    "with tokenizer.as_target_tokenizer():\n",
    "    targets = tokenizer(en_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex for ex in examples[\"zh\"]]\n",
    "    targets = [ex for ex in examples[\"en\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = split_datasets.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=split_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels', 'decoder_input_ids'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(1, 3)])\n",
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   66,    57, 61273,     2,   139,     4,     3, 49328, 49546,   298,\n",
       "         33709,     6, 33154,   122,    79,    32,    12, 51279,     2,   599,\n",
       "             3,    85,   139,    30,    12, 21202,    19,   122,    32, 27457,\n",
       "            29,     3, 51279,     5,     0,  -100,  -100],\n",
       "        [ 5063,     2,     3, 21581,    18,     3, 31103,    30,  6295,     8,\n",
       "             3, 55047,  7327,    29,     3, 32220,  5988,     4,     3, 34626,\n",
       "             2,     6,    73,    54, 48118,  9335,     2,     3,  1445,     4,\n",
       "             3, 30294,   122,    32,  2912,     5,     0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66, 57, 61273, 2, 139, 4, 3, 49328, 49546, 298, 33709, 6, 33154, 122, 79, 32, 12, 51279, 2, 599, 3, 85, 139, 30, 12, 21202, 19, 122, 32, 27457, 29, 3, 51279, 5, 0]\n",
      "[5063, 2, 3, 21581, 18, 3, 31103, 30, 6295, 8, 3, 55047, 7327, 29, 3, 32220, 5988, 4, 3, 34626, 2, 6, 73, 54, 48118, 9335, 2, 3, 1445, 4, 3, 30294, 122, 32, 2912, 5, 0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 3):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ty/1v6fw56935j1czts11tm_7r00000gq/T/ipykernel_42546/200089639.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"sacrebleu\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/load.py:752: FutureWarning: The repository for sacrebleu contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/sacrebleu/sacrebleu.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 46.750469682990165,\n",
       " 'counts': [11, 6, 4, 3],\n",
       " 'totals': [12, 11, 10, 9],\n",
       " 'precisions': [91.66666666666667,\n",
       "  54.54545454545455,\n",
       "  40.0,\n",
       "  33.333333333333336],\n",
       " 'bp': 0.9200444146293233,\n",
       " 'sys_len': 12,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
    "]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 1.683602693167689,\n",
       " 'counts': [1, 0, 0, 0],\n",
       " 'totals': [4, 3, 2, 1],\n",
       " 'precisions': [25.0, 16.666666666666668, 12.5, 12.5],\n",
       " 'bp': 0.10539922456186433,\n",
       " 'sys_len': 4,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\"This This This This\"]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    # In case the model returns more than the prediction logits\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100s in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    return {\"bleu\": result[\"score\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"marian-finetuned-kde4-zh-to-en\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Logging\n",
    "1. 100 句話前後評估都差不多 15s\n",
    "2. 訓練要 9m14s(6min跑循環最後3min不知道衝啥小)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.314296007156372,\n",
       " 'eval_bleu': 28.452433575353787,\n",
       " 'eval_runtime': 14.5938,\n",
       " 'eval_samples_per_second': 0.685,\n",
       " 'eval_steps_per_second': 0.069}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(max_length=max_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [01:54<03:26, 51.52s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      " 67%|██████▋   | 4/6 [04:04<01:50, 55.27s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "100%|██████████| 6/6 [05:52<00:00, 51.73s/it]Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "100%|██████████| 6/6 [05:56<00:00, 59.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 356.7753, 'train_samples_per_second': 0.757, 'train_steps_per_second': 0.017, 'train_loss': 1.84809414545695, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6, training_loss=1.84809414545695, metrics={'train_runtime': 356.7753, 'train_samples_per_second': 0.757, 'train_steps_per_second': 0.017, 'train_loss': 1.84809414545695, 'epoch': 3.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.182519555091858,\n",
       " 'eval_bleu': 46.86788757848948,\n",
       " 'eval_runtime': 17.5937,\n",
       " 'eval_samples_per_second': 0.568,\n",
       " 'eval_steps_per_second': 0.057,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(max_length=max_target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n",
      "model.safetensors: 100%|██████████| 310M/310M [04:16<00:00, 1.21MB/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/charliealex123/marian-finetuned-kde4-zh-to-en/commit/b395ea3d3c31553cc64dd4d210c8a41f2ce6bbdc', commit_message='Training complete', commit_description='', oid='b395ea3d3c31553cc64dd4d210c8a41f2ce6bbdc', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub(tags=\"translation\", commit_message=\"Training complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 完整循環"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"], collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'charliealex123/marian-finetuned-kde4-zh-to-en'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import Repository, get_full_repo_name\n",
    "\n",
    "model_name = \"marian-finetuned-kde4-zh-to-en\"\n",
    "repo_name = get_full_repo_name(model_name)\n",
    "repo_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/charliealex123/marian-finetuned-kde4-zh-to-en into local empty directory.\n",
      "Download file model.safetensors:   0%|          | 17.5k/296M [00:00<?, ?B/s]\n",
      "Download file model.safetensors: 100%|█████████▉| 294M/296M [02:55<00:00, 1.45MB/s] \n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Download file model.safetensors: 100%|██████████| 296M/296M [03:10<00:00, 1.45MB/s]\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Download file model.safetensors: 100%|██████████| 296M/296M [06:03<00:00, 852kB/s] \n",
      "Download file training_args.bin: 100%|██████████| 4.74k/4.74k [06:03<?, ?B/s]\n",
      "\n",
      "\u001b[A\n",
      "Clean file training_args.bin: 100%|██████████| 4.74k/4.74k [06:03<00:00, 10.5B/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Clean file model.safetensors: 100%|██████████| 296M/296M [03:06<00:00, 1.66MB/s]\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"/Users/alexlo/Desktop/Project/Chai_Trans/marian-finetuned-kde4-zh-to-en-local\"\n",
    "repo = Repository(output_dir, clone_from=repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # Some simple post-processing\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "    return decoded_preds, decoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "from getpass import getpass\n",
    "\n",
    "# 填寫用戶名和密碼\n",
    "# username = input(\"Enter your username: \")\n",
    "# password = getpass(\"Enter your password: \")\n",
    "model_path = \"/Users/alexlo/Desktop/Project/Chai_Trans/marian-finetuned-kde4-zh-to-en\"  # 模型文件的路徑\n",
    "\n",
    "# 認證並創建API\n",
    "api = HfApi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:15<00:00,  7.52s/it]t]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, BLEU score: 40.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:14<00:00,  7.15s/it]t]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, BLEU score: 49.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n",
      "100%|██████████| 2/2 [00:14<00:00,  7.32s/it]t]\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 512, 'num_beams': 6, 'bad_words_ids': [[65000]], 'forced_eos_token_id': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, BLEU score: 48.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            generated_tokens = accelerator.unwrap_model(model).generate(\n",
    "                batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                max_length=128,\n",
    "            )\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        generated_tokens = accelerator.pad_across_processes(\n",
    "            generated_tokens, dim=1, pad_index=tokenizer.pad_token_id\n",
    "        )\n",
    "        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(generated_tokens)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        decoded_preds, decoded_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(f\"epoch {epoch}, BLEU score: {results['score']:.2f}\")\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        # api.upload_folder(token=\"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\",\n",
    "        #         folder_path='/Users/alexlo/Desktop/Project/Chai_Trans/marian-finetuned-kde4-zh-to-en',\n",
    "        #         repo_id=repo_name,\n",
    "        #         commit_message=f\"Training in progress epoch {epoch}\", \n",
    "        #         )\n",
    "        repo.push_to_hub(\n",
    "            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9:55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): SiLU()\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (activation_fn): SiLU()\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.upload_folder(token=\"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\",\n",
    "        folder_path='/Users/alexlo/Desktop/Project/Chai_Trans/marian-finetuned-kde4-zh-to-en',\n",
    "        repo_id=repo_name,\n",
    "        commit_message=f\"Training in progress epoch {epoch}\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.push_to_hub(\n",
    "    commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "HfApi.upload_file() missing 2 required keyword-only arguments: 'path_or_fileobj' and 'path_in_repo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/alexlo/Desktop/Project/Chai_Trans/test.ipynb 儲存格 46\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/alexlo/Desktop/Project/Chai_Trans/test.ipynb#Y150sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m api\u001b[39m.\u001b[39;49mupload_file(token\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mhf_CncNOiSoVwkdpqWjljyCkUBMTUDkoNCwBP\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexlo/Desktop/Project/Chai_Trans/test.ipynb#Y150sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         repo_id\u001b[39m=\u001b[39;49mrepo_name,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexlo/Desktop/Project/Chai_Trans/test.ipynb#Y150sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         commit_message\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mTraining in progress epoch \u001b[39;49m\u001b[39m{\u001b[39;49;00mepoch\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/alexlo/Desktop/Project/Chai_Trans/test.ipynb#Y150sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/huggingface_hub/hf_api.py:1208\u001b[0m, in \u001b[0;36mfuture_compatible.<locals>._inner\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_as_future(fn, \u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1207\u001b[0m \u001b[39m# Otherwise, call the function normally\u001b[39;00m\n\u001b[0;32m-> 1208\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: HfApi.upload_file() missing 2 required keyword-only arguments: 'path_or_fileobj' and 'path_in_repo'"
     ]
    }
   ],
   "source": [
    "api.upload_file(token=\"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\",\n",
    "        repo_id=repo_name,\n",
    "        commit_message=f\"Training in progress epoch {epoch}\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(workdata_path)\n",
    "raw_datasets = load_dataset('json', data_files='tmx_zh_en.json') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.safetensors: 100%|██████████| 310M/310M [04:16<00:00, 1.21MB/s] \n",
      "special_tokens_map.json: 100%|██████████| 416/416 [00:00<00:00, 537kB/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_checkpoint = \"charliealex123/marian-finetuned-kde4-zh-to-en\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48894"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需翻譯句: 如請求項1所述的電路板模組，其中該至少一凹槽包括兩凹槽，該些攝像元件分別設置於該兩凹槽內。\n",
      "原翻譯: The circuit board module according to claim 1, wherein the at least one groove has two grooves, and the two camera elements are respectively disposed in the two grooves.\n",
      "機器學習翻譯: A circuit board module, as described in request 1, in which at least one groove includes two grooves, each of which is set separately in the two grooves.\n",
      "\n",
      "需翻譯句: 在本發明的一實施例中，上述的電路板本體在兩凹槽之間包括一無兩元件導通走線區段，兩攝像元件透過該接電路板彼此電性連接，而無法透過該兩元件導通走線區段電性連接。\n",
      "原翻譯: In an embodiment of the disclosure, the circuit board body includes a conducting wiring section without two elements between the two grooves. The two camera elements are electrically connected to each other through the circuit board, but not electronically connecting to each other through the conducting wiring section without two elements.\n",
      "機器學習翻譯: In an illustration of the disclosure, the above-mentioned circuit board body includes a no-two-component steering line segment between the two grooves, the two camera elements are connected electrically to each other through the circuit board, and cannot be connected electrically through the two parts leading to the line segment.\n",
      "\n",
      "需翻譯句: 如請求項2所述的電路板模組，其中該電路板本體在該兩凹槽之間包括一無兩元件導通走線區段，該兩攝像元件透過該外接電路板彼此電性連接，而無法透過該無兩元件導通走線區段電性連接。\n",
      "原翻譯: The circuit board module according to claim 2, wherein the circuit board body has a conducting wiring section without two elements between the two grooves, and the two camera elements are electrically connected to each other through the circuit board, but not electronically connecting to each other through the conducting wiring section without two elements.\n",
      "機器學習翻譯: The circuit board module, as described in request 2, in which the board body includes a line segment between the two grooves, the two camera elements are connected electrically through the external circuit board, and cannot be connected electrically by the line segment through the non-dividual link.\n",
      "\n",
      "需翻譯句: 一外接電路板，包括兩連接埠，其中該兩連接埠可插拔地連接於該兩板對板連接器，以使該外接電路板電性連接於該電路板本體。\n",
      "原翻譯: an external circuit board having two connection ports pluggablely connected to the two board-to-board connectors, so that the external circuit board is electrically connected to the circuit board body.\n",
      "機器學習翻譯: The outer circuit board, which includes two ports, can be connected interpolated to the two pairs so that the outer circuit board is connected electrically to the board body.\n",
      "\n",
      "需翻譯句: 外接電路板包括兩連接埠，其中兩連接埠可插拔地連接於兩板對板連接器，以使外接電路板電性連接於電路板本體。\n",
      "原翻譯: The external circuit board includes two connection ports pluggablely connected to the two board-to-board connectors, so that the external circuit board is electrically connected to the circuit board body.\n",
      "機器學習翻譯: The external circuit board consists of two ports, two of which can be connected interpolated to the two pairs of panels so that the external circuit board is connected electrically to the board body.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 訓練前0~10\n",
    "for i in range(1000, 1005):\n",
    "    # i = 3\n",
    "    zh_sentence = raw_datasets['train']['zh'][i]\n",
    "    print('需翻譯句:', zh_sentence)\n",
    "    print('原翻譯:', raw_datasets['train']['en'][i])\n",
    "    print('機器學習翻譯:', translator(zh_sentence)[0]['translation_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需翻譯句: 焦距調節機構\n",
      "原翻譯: FOCAL LENGTH ADJUSTMENT MECHANISM\n",
      "機器學習翻譯: Focal length adjustment mechanism\n",
      "\n",
      "需翻譯句: 一種焦距調節機構，適於調節位於一投影機的一殼體內的一焦距調節件。\n",
      "原翻譯: A focal length adjustment mechanism, adapted for adjusting a focal length adjustment device located in a housing of a projector.\n",
      "機器學習翻譯: A focal length adjustment mechanism, suitable for adjusting a focal length adjustment device located in a shell of a projector.\n",
      "\n",
      "需翻譯句: 焦距調節機構包括一旋鈕及一第一行程調整件。\n",
      "原翻譯: The focal length adjustment mechanism includes a knob and a first stroke adjustment member.\n",
      "機器學習翻譯: The focal length adjustment mechanism includes a knob and a first process adjustment member.\n",
      "\n",
      "需翻譯句: 旋鈕局部地外露於殼體。\n",
      "原翻譯: The knob is partially exposed to the housing.\n",
      "機器學習翻譯: The knob is partially exposed to the shell.\n",
      "\n",
      "需翻譯句: 旋鈕轉動，帶動第一行程調整件以第一樞軸為中心轉動。\n",
      "原翻譯: The knob rotates to drive the first stroke adjustment member to rotate along the first pivot.\n",
      "機器學習翻譯: The knob rotates, with the first movement adjustment member rotates along the first pivot.\n",
      "\n",
      "需翻譯句: Description of Related Art\n",
      "原翻譯: Description of Related Art\n",
      "機器學習翻譯: Description of Retained Art\n",
      "\n",
      "需翻譯句: 一般來說，投影機使用時需要調整鏡頭焦距，以使投影畫面清楚。\n",
      "原翻譯: Generally, when using the projector, the focal length of the lens needs to be adjusted to make the projected image clear.\n",
      "機器學習翻譯: Generally, the projector is used to adjust the focal length of the mirror so that the projector is clear.\n",
      "\n",
      "需翻譯句: 隨著投影機的尺寸越來越小，受限於內部空間的尺寸，光機朝向小型化發展。\n",
      "原翻譯: As the size of a projector becomes smaller, the size of the internal space is limited, and light engines are developing towards miniaturization.\n",
      "機器學習翻譯: As the size of the projector becomes smaller and limited to the size of the internal space, the light machine moves towards miniaturization.\n",
      "\n",
      "需翻譯句: 隨著投影機的尺寸越來越小，受限於內部空間的尺寸，光機朝向小型化發展。這使得光機的鏡頭較難對焦。\n",
      "原翻譯: As the size of a projector becomes smaller, the size of the internal space is limited, and light engines are developing towards miniaturization, which makes the lens of the light engines more difficult to focus.\n",
      "機器學習翻譯: As the size of the projector becomes smaller, limited to the size of the internal space, the light machine moves towards miniaturization. This makes the mirror of the light machine harder to focus.\n",
      "\n",
      "需翻譯句: WHAT IS CLAIMED IS:\n",
      "原翻譯: WHAT IS CLAIMED IS:\n",
      "機器學習翻譯: WHAT IS CLAIMED IS:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 拿100句話訓練後\n",
    "for i in range(0, 10):\n",
    "    # i = 3\n",
    "    zh_sentence = raw_datasets['train']['zh'][i]\n",
    "    print('需翻譯句:', zh_sentence)\n",
    "    print('原翻譯:', raw_datasets['train']['en'][i])\n",
    "    print('機器學習翻譯:', translator(zh_sentence)[0]['translation_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需翻譯句: 如請求項1所述的電路板模組，其中該至少一凹槽包括兩凹槽，該些攝像元件分別設置於該兩凹槽內。\n",
      "原翻譯: The circuit board module according to claim 1, wherein the at least one groove has two grooves, and the two camera elements are respectively disposed in the two grooves.\n",
      "機器學習翻譯: If requested, the circuit board module described in item 1 should include at least two diagonals in at least one groove in which the camera element is separated into two diagonal slots.\n",
      "\n",
      "需翻譯句: 在本發明的一實施例中，上述的電路板本體在兩凹槽之間包括一無兩元件導通走線區段，兩攝像元件透過該接電路板彼此電性連接，而無法透過該兩元件導通走線區段電性連接。\n",
      "原翻譯: In an embodiment of the disclosure, the circuit board body includes a conducting wiring section without two elements between the two grooves. The two camera elements are electrically connected to each other through the circuit board, but not electronically connecting to each other through the conducting wiring section without two elements.\n",
      "機器學習翻譯: In the case of this invention, the above-mentioned circuit board body consists of a no-two-part line link between the two dents, which is connected electrically to each other through the circuit board and cannot be connected electrically through the two-part link.\n",
      "\n",
      "需翻譯句: 如請求項2所述的電路板模組，其中該電路板本體在該兩凹槽之間包括一無兩元件導通走線區段，該兩攝像元件透過該外接電路板彼此電性連接，而無法透過該無兩元件導通走線區段電性連接。\n",
      "原翻譯: The circuit board module according to claim 2, wherein the circuit board body has a conducting wiring section without two elements between the two grooves, and the two camera elements are electrically connected to each other through the circuit board, but not electronically connecting to each other through the conducting wiring section without two elements.\n",
      "機器學習翻譯: If requested, the circuit board module, which includes a no-two-part line link between the two grooves, is electrically connected through the outside circuit board and cannot be electrically connected through the no-two link.\n",
      "\n",
      "需翻譯句: 一外接電路板，包括兩連接埠，其中該兩連接埠可插拔地連接於該兩板對板連接器，以使該外接電路板電性連接於該電路板本體。\n",
      "原翻譯: an external circuit board having two connection ports pluggablely connected to the two board-to-board connectors, so that the external circuit board is electrically connected to the circuit board body.\n",
      "機器學習翻譯: The outer circuit board consists of two ports, of which the two docks can be connected interpolated to the two pairs so that the outer circuit board will be connected electrically to the board itself.\n",
      "\n",
      "需翻譯句: 外接電路板包括兩連接埠，其中兩連接埠可插拔地連接於兩板對板連接器，以使外接電路板電性連接於電路板本體。\n",
      "原翻譯: The external circuit board includes two connection ports pluggablely connected to the two board-to-board connectors, so that the external circuit board is electrically connected to the circuit board body.\n",
      "機器學習翻譯: The outer circuit board consists of two ports, two of which can be connected interpolated to two pairs to make the outer circuit board electrically connected to the original circuit board.\n",
      "\n",
      "需翻譯句: 如請求項1所述的電路板模組，其中該外接電路板包括一主區段及從該主區段延伸出的兩分支，該兩連接埠分別設置於該兩分支且可插拔地連接於該兩板對板連接器。\n",
      "原翻譯: The circuit board module according to claim 1, wherein the external circuit board has a main section and two branches extending from the main section, and the two connection ports are respectively disposed on the two branches and pluggably connected to the two board-to-board connectors.\n",
      "機器學習翻譯: If requested, the circuit board module, which includes a main section and two branches extending from the main section, shall be separated between the two branches and may be plugged into the two pairs.\n",
      "\n",
      "需翻譯句: 如請求項1所述的電路板模組，更包括：\n",
      "原翻譯: The circuit board module according to claim 1, further comprising:\n",
      "機器學習翻譯: If requested, the circuit board module described in item 1, more specifically:\n",
      "\n",
      "需翻譯句: 在本發明的一實施例中，上述的電路板模組更包括至少一第二電子元件，設置於表面且電性連接於電路板本體，各第二電子元件的高度小於各攝像元件的高度。\n",
      "原翻譯: In an embodiment of the disclosure, the circuit board module further includes at least one second electronic element disposed on the surface and electrically connected to the circuit board body. The height of each second electronic element is smaller than the height of each camera element.\n",
      "機器學習翻譯: In the case of this invention, the above-mentioned circuit panel module consists of at least one second electrical element, which is designed on the surface and is electrically connected to the original circuit board, with each second electrical element having a height of less than the height of each camera element.\n",
      "\n",
      "需翻譯句: 至少一第二電子元件，設置於該表面且電性連接於該電路板本體，各該第二電子元件的高度小於各該攝像元件的高度。\n",
      "原翻譯: at least one second electronic element disposed on the surface and electrically connected to the circuit board body, the height of each second electronic element is smaller than the height of each camera element.\n",
      "機器學習翻譯: At least one second electrical element, which is placed on that surface and is electrically connected to the original circuit board, shall each be of a height less than the height of the respective camera element.\n",
      "\n",
      "需翻譯句: 如請求項6所述的電路板模組，其中各該第一電子元件包括一麥克風，各該第二電子元件包括一光源。\n",
      "原翻譯: The circuit board module according to claim 6, wherein each of the first electronic elements has a microphone, and each of the second electronic elements has a light source.\n",
      "機器學習翻譯: If requested, the circuit board module described in item 6, each of which includes a microphone and each of which includes a light source.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 訓練前1000~1010\n",
    "for i in range(1000, 1010):\n",
    "    # i = 3\n",
    "    zh_sentence = raw_datasets['train']['zh'][i]\n",
    "    print('需翻譯句:', zh_sentence)\n",
    "    print('原翻譯:', raw_datasets['train']['en'][i])\n",
    "    print('機器學習翻譯:', translator(zh_sentence)[0]['translation_text'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "需翻譯句: 如請求項1所述的電路板模組，其中該至少一凹槽包括兩凹槽，該些攝像元件分別設置於該兩凹槽內。\n",
      "原翻譯: The circuit board module according to claim 1, wherein the at least one groove has two grooves, and the two camera elements are respectively disposed in the two grooves.\n",
      "機器學習翻譯: If requested, the circuit board module described in item 1 should include at least two diagonals in at least one groove in which the camera element is separated into two diagonal slots.\n",
      "\n",
      "需翻譯句: 在本發明的一實施例中，上述的電路板本體在兩凹槽之間包括一無兩元件導通走線區段，兩攝像元件透過該接電路板彼此電性連接，而無法透過該兩元件導通走線區段電性連接。\n",
      "原翻譯: In an embodiment of the disclosure, the circuit board body includes a conducting wiring section without two elements between the two grooves. The two camera elements are electrically connected to each other through the circuit board, but not electronically connecting to each other through the conducting wiring section without two elements.\n",
      "機器學習翻譯: In the case of this invention, the above-mentioned circuit board body consists of a no-two-part line link between the two dents, which is connected electrically to each other through the circuit board and cannot be connected electrically through the two-part link.\n",
      "\n",
      "需翻譯句: 如請求項2所述的電路板模組，其中該電路板本體在該兩凹槽之間包括一無兩元件導通走線區段，該兩攝像元件透過該外接電路板彼此電性連接，而無法透過該無兩元件導通走線區段電性連接。\n",
      "原翻譯: The circuit board module according to claim 2, wherein the circuit board body has a conducting wiring section without two elements between the two grooves, and the two camera elements are electrically connected to each other through the circuit board, but not electronically connecting to each other through the conducting wiring section without two elements.\n",
      "機器學習翻譯: If requested, the circuit board module, which includes a no-two-part line link between the two grooves, is electrically connected through the outside circuit board and cannot be electrically connected through the no-two link.\n",
      "\n",
      "需翻譯句: 一外接電路板，包括兩連接埠，其中該兩連接埠可插拔地連接於該兩板對板連接器，以使該外接電路板電性連接於該電路板本體。\n",
      "原翻譯: an external circuit board having two connection ports pluggablely connected to the two board-to-board connectors, so that the external circuit board is electrically connected to the circuit board body.\n",
      "機器學習翻譯: The outer circuit board consists of two ports, of which the two docks can be connected interpolated to the two pairs so that the outer circuit board will be connected electrically to the board itself.\n",
      "\n",
      "需翻譯句: 外接電路板包括兩連接埠，其中兩連接埠可插拔地連接於兩板對板連接器，以使外接電路板電性連接於電路板本體。\n",
      "原翻譯: The external circuit board includes two connection ports pluggablely connected to the two board-to-board connectors, so that the external circuit board is electrically connected to the circuit board body.\n",
      "機器學習翻譯: The outer circuit board consists of two ports, two of which can be connected interpolated to two pairs to make the outer circuit board electrically connected to the original circuit board.\n",
      "\n",
      "需翻譯句: 如請求項1所述的電路板模組，其中該外接電路板包括一主區段及從該主區段延伸出的兩分支，該兩連接埠分別設置於該兩分支且可插拔地連接於該兩板對板連接器。\n",
      "原翻譯: The circuit board module according to claim 1, wherein the external circuit board has a main section and two branches extending from the main section, and the two connection ports are respectively disposed on the two branches and pluggably connected to the two board-to-board connectors.\n",
      "機器學習翻譯: If requested, the circuit board module, which includes a main section and two branches extending from the main section, shall be separated between the two branches and may be plugged into the two pairs.\n",
      "\n",
      "需翻譯句: 如請求項1所述的電路板模組，更包括：\n",
      "原翻譯: The circuit board module according to claim 1, further comprising:\n",
      "機器學習翻譯: If requested, the circuit board module described in item 1, more specifically:\n",
      "\n",
      "需翻譯句: 在本發明的一實施例中，上述的電路板模組更包括至少一第二電子元件，設置於表面且電性連接於電路板本體，各第二電子元件的高度小於各攝像元件的高度。\n",
      "原翻譯: In an embodiment of the disclosure, the circuit board module further includes at least one second electronic element disposed on the surface and electrically connected to the circuit board body. The height of each second electronic element is smaller than the height of each camera element.\n",
      "機器學習翻譯: In the case of this invention, the above-mentioned circuit panel module consists of at least one second electrical element, which is designed on the surface and is electrically connected to the original circuit board, with each second electrical element having a height of less than the height of each camera element.\n",
      "\n",
      "需翻譯句: 至少一第二電子元件，設置於該表面且電性連接於該電路板本體，各該第二電子元件的高度小於各該攝像元件的高度。\n",
      "原翻譯: at least one second electronic element disposed on the surface and electrically connected to the circuit board body, the height of each second electronic element is smaller than the height of each camera element.\n",
      "機器學習翻譯: At least one second electrical element, which is placed on that surface and is electrically connected to the original circuit board, shall each be of a height less than the height of the respective camera element.\n",
      "\n",
      "需翻譯句: 如請求項6所述的電路板模組，其中各該第一電子元件包括一麥克風，各該第二電子元件包括一光源。\n",
      "原翻譯: The circuit board module according to claim 6, wherein each of the first electronic elements has a microphone, and each of the second electronic elements has a light source.\n",
      "機器學習翻譯: If requested, the circuit board module described in item 6, each of which includes a microphone and each of which includes a light source.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 訓練後1000~1010\n",
    "for i in range(1000, 1010):\n",
    "    # i = 3\n",
    "    zh_sentence = raw_datasets['train']['zh'][i]\n",
    "    print('需翻譯句:', zh_sentence)\n",
    "    print('原翻譯:', raw_datasets['train']['en'][i])\n",
    "    print('機器學習翻譯:', translator(zh_sentence)[0]['translation_text'])\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
